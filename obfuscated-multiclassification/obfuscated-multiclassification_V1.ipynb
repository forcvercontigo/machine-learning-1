{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Concatenate, Dense, Dropout, Softmax\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./xtrain_obfuscated.txt') as fp:\n",
    "    data = fp.read().split('\\n')\n",
    "with open('./ytrain.txt') as fp:\n",
    "    label = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 26\n",
    "max_len = 0\n",
    "for sent in data:\n",
    "    max_len = max(max_len, len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label)):\n",
    "    label[i] = int(label[i])\n",
    "label = np.asarray(label)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "label = label.reshape(-1,1)\n",
    "y_train_data = ohe.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(data)):\n",
    "    temp = np.zeros((max_len, max_char))\n",
    "    for j in range(len(data[i])):\n",
    "        temp[j][ord(data[i][j])-97] = 1\n",
    "    X_train.append(temp)\n",
    "X_train = np.asarray(X_train)\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1], X_train.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convSize_1 = 3\n",
    "convSize_2 = 4\n",
    "convSize_3 = 5\n",
    "convSize_4 = 6\n",
    "convSize_5 = 7\n",
    "convSize_6 = 8\n",
    "convSize_7 = 9\n",
    "convSize_8 = 10\n",
    "\n",
    "inputLayer = Input(shape=(X_train[0].shape[0],X_train[0].shape[1],1))\n",
    "convLayer_1 = Conv2D(filters=256, kernel_size=(convSize_1,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_2 = Conv2D(filters=256, kernel_size=(convSize_2,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_3 = Conv2D(filters=256, kernel_size=(convSize_3,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_4 = Conv2D(filters=256, kernel_size=(convSize_4,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_5 = Conv2D(filters=256, kernel_size=(convSize_5,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_6 = Conv2D(filters=256, kernel_size=(convSize_6,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_7 = Conv2D(filters=256, kernel_size=(convSize_7,X_train[0].shape[1]))(inputLayer)\n",
    "convLayer_8 = Conv2D(filters=256, kernel_size=(convSize_8,X_train[0].shape[1]))(inputLayer)\n",
    "\n",
    "dropout_1 = Dropout(0.5)(convLayer_1)\n",
    "dropout_2 = Dropout(0.5)(convLayer_2)\n",
    "dropout_3 = Dropout(0.5)(convLayer_3)\n",
    "dropout_4 = Dropout(0.5)(convLayer_4)\n",
    "dropout_5 = Dropout(0.5)(convLayer_5)\n",
    "dropout_6 = Dropout(0.5)(convLayer_6)\n",
    "dropout_7 = Dropout(0.5)(convLayer_7)\n",
    "dropout_8 = Dropout(0.5)(convLayer_8)\n",
    "\n",
    "maxPool_1 = MaxPooling2D(pool_size=(max_len-convSize_1+1, 1))(dropout_1)\n",
    "maxPool_2 = MaxPooling2D(pool_size=(max_len-convSize_2+1, 1))(dropout_2)\n",
    "maxPool_3 = MaxPooling2D(pool_size=(max_len-convSize_3+1, 1))(dropout_3)\n",
    "maxPool_4 = MaxPooling2D(pool_size=(max_len-convSize_4+1, 1))(dropout_4)\n",
    "maxPool_5 = MaxPooling2D(pool_size=(max_len-convSize_5+1, 1))(dropout_5)\n",
    "maxPool_6 = MaxPooling2D(pool_size=(max_len-convSize_6+1, 1))(dropout_6)\n",
    "maxPool_7 = MaxPooling2D(pool_size=(max_len-convSize_7+1, 1))(dropout_7)\n",
    "maxPool_8 = MaxPooling2D(pool_size=(max_len-convSize_8+1, 1))(dropout_8)\n",
    "\n",
    "flatten_1 = Flatten()(maxPool_1)\n",
    "flatten_2 = Flatten()(maxPool_2)\n",
    "flatten_3 = Flatten()(maxPool_3)\n",
    "flatten_4 = Flatten()(maxPool_4)\n",
    "flatten_5 = Flatten()(maxPool_5)\n",
    "flatten_6 = Flatten()(maxPool_6)\n",
    "flatten_7 = Flatten()(maxPool_7)\n",
    "flatten_8 = Flatten()(maxPool_8)\n",
    "\n",
    "mergedLayer = Concatenate(axis=1)([flatten_1, flatten_2, flatten_3, flatten_4, flatten_5, flatten_6, flatten_7, flatten_8])\n",
    "dense_1 = Dense(1024, activation='relu')(mergedLayer)\n",
    "dropout_9 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(128, activation='relu')(dropout_9)\n",
    "dropout_10 = Dropout(0.5)(dense_2)\n",
    "\n",
    "result = Dense(12, activation='softmax')(dropout_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 452, 26, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 450, 1, 256)  20224       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 449, 1, 256)  26880       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 448, 1, 256)  33536       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 447, 1, 256)  40192       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 446, 1, 256)  46848       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 445, 1, 256)  53504       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 444, 1, 256)  60160       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 443, 1, 256)  66816       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 450, 1, 256)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 449, 1, 256)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 448, 1, 256)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 447, 1, 256)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 446, 1, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 445, 1, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 444, 1, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 443, 1, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 256)          0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 256)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 256)          0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 256)          0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 256)          0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2048)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          131200      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           1548        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,579,084\n",
      "Trainable params: 2,579,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputLayer, result)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tensorboard = TensorBoard(log_dir='./logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26010 samples, validate on 6503 samples\n",
      "Epoch 1/20\n",
      "26010/26010 [==============================] - 58s 2ms/step - loss: 2.3577 - acc: 0.1577 - val_loss: 2.2197 - val_acc: 0.2843\n",
      "Epoch 2/20\n",
      "26010/26010 [==============================] - 53s 2ms/step - loss: 1.7494 - acc: 0.3982 - val_loss: 1.3848 - val_acc: 0.5647\n",
      "Epoch 3/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 1.2516 - acc: 0.5706 - val_loss: 1.1087 - val_acc: 0.6488\n",
      "Epoch 4/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 1.0095 - acc: 0.6611 - val_loss: 0.9242 - val_acc: 0.7264\n",
      "Epoch 5/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.8535 - acc: 0.7151 - val_loss: 0.8302 - val_acc: 0.7598\n",
      "Epoch 6/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.7611 - acc: 0.7498 - val_loss: 0.7642 - val_acc: 0.7789\n",
      "Epoch 7/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.6681 - acc: 0.7804 - val_loss: 0.6857 - val_acc: 0.7898\n",
      "Epoch 8/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.6022 - acc: 0.7995 - val_loss: 0.6816 - val_acc: 0.7855\n",
      "Epoch 9/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.5427 - acc: 0.8221 - val_loss: 0.6470 - val_acc: 0.7938\n",
      "Epoch 10/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.5130 - acc: 0.8317 - val_loss: 0.6614 - val_acc: 0.7852\n",
      "Epoch 11/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.4760 - acc: 0.8451 - val_loss: 0.5501 - val_acc: 0.8268\n",
      "Epoch 12/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.4275 - acc: 0.8645 - val_loss: 0.5685 - val_acc: 0.8189\n",
      "Epoch 13/20\n",
      "26010/26010 [==============================] - 52s 2ms/step - loss: 0.4135 - acc: 0.8618 - val_loss: 0.5094 - val_acc: 0.8395\n",
      "Epoch 14/20\n",
      "26010/26010 [==============================] - 54s 2ms/step - loss: 0.3676 - acc: 0.8819 - val_loss: 0.5269 - val_acc: 0.8310\n",
      "Epoch 15/20\n",
      "26010/26010 [==============================] - 54s 2ms/step - loss: 0.3711 - acc: 0.8795 - val_loss: 0.4937 - val_acc: 0.8484\n",
      "Epoch 16/20\n",
      "26010/26010 [==============================] - 54s 2ms/step - loss: 0.3327 - acc: 0.8927 - val_loss: 0.5272 - val_acc: 0.8278\n",
      "Epoch 17/20\n",
      "26010/26010 [==============================] - 55s 2ms/step - loss: 0.3235 - acc: 0.8948 - val_loss: 0.4982 - val_acc: 0.8401\n",
      "Epoch 18/20\n",
      "26010/26010 [==============================] - 55s 2ms/step - loss: 0.3082 - acc: 0.8998 - val_loss: 0.4750 - val_acc: 0.8515\n",
      "Epoch 19/20\n",
      "26010/26010 [==============================] - 55s 2ms/step - loss: 0.2878 - acc: 0.9081 - val_loss: 0.4847 - val_acc: 0.8475\n",
      "Epoch 20/20\n",
      "19968/26010 [======================>.......] - ETA: 11s - loss: 0.2803 - acc: 0.9096"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[512,256,450,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/dropout_1/cond/Merge_grad/cond_grad\"], data_format=\"NCHW\", ksize=[1, 1, 450, 1], padding=\"VALID\", strides=[1, 1, 450, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge, max_pooling2d_1/MaxPool, training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dfe66aceff3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         callbacks=[tensorboard])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[512,256,450,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/dropout_1/cond/Merge_grad/cond_grad\"], data_format=\"NCHW\", ksize=[1, 1, 450, 1], padding=\"VALID\", strides=[1, 1, 450, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge, max_pooling2d_1/MaxPool, training/Adam/gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train_data, \n",
    "        batch_size=512, \n",
    "        verbose=1, epochs=20, \n",
    "        shuffle=True, \n",
    "        validation_split=0.2,\n",
    "        callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('8_layer_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
